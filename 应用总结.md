## SimBricks 支持的几大类应用模拟（网络相关）：

---

### 一、网络性能基准测试 

1. `Ping`：基础连通性测试，检查基本的网络是否联通，并粗略地测量往返延迟（RTT）。它只生成一条简单的命令：`ping <服务器IP> -c 10`。这会告诉模拟的客户端向服务器发送10个ICMP回显请求包，然后自动停止。

```python
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return [f'ping {self.server_ip} -c 10']
```

对应 simbricks 中的测试脚本：**simple_ping.py**



2. `iperf`：吞吐量测量工具，用于测量网络能够达到的最大**吞吐量**（即带宽）。SimBricks 提供了一套完整的类，用于在 TCP 和 UDP 模式下运行 `iperf`。

```python
class IperfTCPServer(AppConfig):
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return ['iperf -s -l 32M -w 32M']
    
class IperfTCPClient(AppConfig):
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        cmds = [
            'sleep 1',
            'iperf -l 32M -w 32M  -c ' + self.server_ip + ' -i 1 -P ' +
            str(self.procs)
        ]
        # ...
        return cmds
```

 对应 simbricks 中的测试脚本：**gt_tcp_multi.py, gt_tcp_single.py, iperf_client_server_pair.py, modetcp.py, qemu_tcp_multi.py, qemu_tcp_single.py, gt_udp_multi.py, qemu_udp_multi.py, qemu_udp_single.py, scalability.py, scale_host.py, scale_load.py, determ.py, f7_scale.py**



3. `netperf`：高级吞吐量与延迟测试，`netperf` 是另一个行业标准的测试工具，模拟了大量的请求-响应式通信。客户端会执行两种测试：首先是一个标准的流式吞吐量测试，然后是一个专门的延迟测试。

```python
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return [
            'netserver', # 客户端也运行守护进程，用于反向测试
            'sleep 0.5',
            # 吞吐量测试
            f'netperf -H {self.server_ip} -l {self.duration_tp}',
            # 延迟测试
            f'netperf -H {self.server_ip} -l {self.duration_lat} -t TCP_RR'
            ' -- -o mean_latency,p50_latency,p90_latency,p99_latency'
        ]
```

对应 simbricks 中的测试脚本：**dist_multinet.py, dist_netperf.py, netperf.py, pci_validation.py, corundum_pcilat.py, f9_latency.py, t1_netperf.py**



4. 针对拥塞控制的 `iperf` 专项测试，基于iperf，**测试不同的 TCP 拥塞控制算法**。

- **DCTCP**: `DctcpClient` 和 `DctcpServer` 类添加了 `-Z dctcp` 标志。这告诉 `iperf` 使用其内置的 DCTCP 算法实现，这是一种在数据中心很常见的算法。
- **通用TCP拥塞控制**: `TcpCongClient` 和 `TcpCongServer` 类**没有**在 `iperf` 命令中指定算法。相反，它们依赖于在模拟节点操作系统层面设置的拥塞控制算法。这使得研究人员可以测试模拟的 Linux 内核所支持的任何算法（例如 BBR、CUBIC 等）。

```python
class DctcpServer(AppConfig):
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return ['iperf -s -w 1M -Z dctcp']

class TcpCongClient(AppConfig):
    def run_cmds(self, node):
        # ...
        return [
            'sleep 1',
            f'iperf -w 1M -c {self.server_ip} -i 1',
            # ...
        ]
```

对应 simbricks 中的测试脚本：**dctcp.py, f1_dctcp.py, e2e_automatic_split.py, e2e_cc.py, e2e_split.py, tcp_congestion_control.py**



### 二、Web 服务器与客户端

1. 服务器基类：HTTPD， 是所有Web服务器配置的“模板”或基类。它定义了启动一个Web服务器的通用逻辑。

```python
class HTTPD(AppConfig):
    # ...
    def prepare_pre_cp(self) -> tp.List[str]:
        return [
            # 1. 创建Web服务器需要的目录
            'mkdir -p /srv/www/htdocs/ /tmp/lighttpd/',
            # 2. 创建一个特定大小的、名为'file'的文件，供客户端下载
            f'dd if=/dev/zero of=/srv/www/htdocs/file bs={self.file_size} count=1'
        ]

    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return [
            # 3. 进入lighttpd的源码目录
            f'cd {self.httpd_dir}/src/',
            # 4. 启动lighttpd服务进程
            f'./lighttpd -D -f ../doc/config/{self.mtcp_config} ...'
        ]
```

​	在仿真开始前，这个方法负责准备服务器环境。它创建了Web根目录 `/srv/www/htdocs/`，然后使用 `dd` 命令生成一个大小由 `self.file_size` 控制的测试文件。这个文件就是后续客户端请求的目标。

​	启动 `lighttpd` Web服务器。它会进入到由 `self.httpd_dir` 指定的目录，然后执行 `lighttpd` 命令，并传入配置文件和线程数等参数。

2. `HTTPD` 的子类：实现不同版本的服务器

`HTTPDLinux`、`HTTPDLinuxRPO` 和 `HTTPDMtcp` 三个子类：继承 `HTTPD` 的所有行为，只修改一件事——**指定 `lighttpd` 程序所在的目录 (`self.httpd_dir`)**。

- **`HTTPDLinux`**: 使用 `/root/mtcp/apps/lighttpd-mtlinux` 目录下的版本，这代表一个为**标准Linux网络栈**编译的 `lighttpd`。
- **`HTTPDMtcp`**: 使用 `/root/mtcp/apps/lighttpd-mtcp` 目录下的版本，这代表一个为 **MTCP (一种高性能的用户态TCP协议栈)** 编译的 `lighttpd`。它还额外执行了一些 `cp` 和 `sed` 命令，来专门为 MTCP 环境准备配置文件。

通过选择不同的子类，可以轻松地在同一个实验中对比标准内核网络栈和高性能用户态网络栈的Web服务性能。

3. 客户端基类：HTTPC，Web客户端的基类，它使用 `ab` (Apache Bench) 工具来对服务器施加压力。

```python
class HTTPC(AppConfig):
    # ...
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return [
            # 1. 进入ab工具所在的目录
            f'cd {self.ab_dir}/support/',
            # 2. 执行ab命令
            f'./ab -N {self.threads} -c {self.conns} -n {self.requests} {self.server_ip}{self.url}'
        ]
```

4. `HTTPC` 的子类：适配不同网络栈的客户端

与服务器端类似，`HTTPCLinux` 和 `HTTPCMtcp` 的作用是指定使用哪个版本的 `ab` 工具。

- **`HTTPCLinux`**: 使用为**标准Linux网络栈**编译的 `ab`。
- **`HTTPCMtcp`**: 使用为 **MTCP** 编译的 `ab`，并执行额外的文件准备工作。

对应 simbricks 中的测试脚本：**mtcp_httpd.py**



### 三、分布式共识协议

利用仿真环境来评测和对比**复杂的分布式算法**

1. `NOPaxos` 协议 

`NOPaxos` 是一种为了在广域网上实现高性能而设计的共识协议。SimBricks 为它提供了完整的模拟组件，包括三种不同的角色：副本（Replica）、客户端（Client）和序列器（Sequencer）。

![![NOPaxos的一个整体架构](./NOPaxos的整体架构.png)](https://segmentfault.com/img/bV4EE0?w=964&h=549)

- **`NOPaxosReplica` (副本)**: 协议的核心服务器，负责存储数据和执行状态机。

```python
def run_cmds(self, node: NodeConfig) -> tp.List[str]:
    return [
        '/root/nopaxos/bench/replica -c /root/nopaxos.config -i ' +
        str(self.index) + ' -m nopaxos'
    ]
```

​	启动 `replica` 程序，为每个副本指定一个独一无二的ID，告诉程序以 **NOPaxos** 模式运行。

- **`NOPaxosSequencer` (序列器)**:  NOPaxos 协议中一个特殊的角色，负责对客户端请求进行排序。

```python
def run_cmds(self, node: NodeConfig) -> tp.List[str]:
    return [
        '/root/nopaxos/sequencer/sequencer ... -m nopaxos'
    ]
```

​	启动一个独立的 `sequencer` 进程。

- **`NOPaxosClient` (客户端)**: 模拟向系统发起请求的用户。

```python
def run_cmds(self, node: NodeConfig) -> tp.List[str]:
    cmds = []
    for ip in self.server_ips:
        cmds.append('ping -c 2 ' + ip) # 先 ping 所有服务器确保网络就绪
    cmd = '/root/nopaxos/bench/client ... -m nopaxos -h ' + node.ip
    # ...
    cmds.append(cmd)
    # ...
    return cmds
```

​	首先会 `ping` 所有服务器以确保网络启动完成，然后再启动 `client` 基准测试程序，向共识系统提交负载。



2. `VR` (Viewstamped Replication) 协议

`Viewstamped Replication`，一种经典的、比 Paxos 更早提出的共识算法。SimBricks 通过使用**同一个 `nopaxos` 基准测试程序**来模拟它，仅仅是通过改变运行模式的参数。

对应 simbricks 中的测试脚本：**nopaxos.py**



### 四、键值存储 / 缓存系统

`Memcached` 缓存系统

1. `MemcachedServer`：缓存服务器

```python
class MemcachedServer(AppConfig):
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        return ['memcached -u root -t 1 -c 4096']
```

​	启动 `memcached` 服务的主程序。

2. `MemcachedClient`：缓存客户端 

```python
class MemcachedClient(AppConfig):
    def __init__(self) -> None:
        # ... 初始化参数 ...
        self.server_ips = ['10.0.0.1']
        self.threads = 1
        self.concurrency = 1
        self.throughput = '1k' # 每秒 1000 次操作

    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        # 1. 格式化服务器地址列表
        servers = [ip + ':11211' for ip in self.server_ips]
        servers = ','.join(servers)
        # 2. 构建 memaslap 命令
        return [(
            f'memaslap --binary --time 10s --server={servers}'
            f' --thread={self.threads} --concurrency={self.concurrency}'
            f' --tps={self.throughput} --verbose'
        )]
```

​	构建 `memaslap` 命令，启动压力测试工具。

对应 simbricks 中的测试脚本：**dist_memcache.py**



### 五、RPC 微基准测试

​	使用一个名为 `tasbench` 的测试套件，专门用于模拟和评测**微服务架构**中常见的、大量且快速的**远程过程调用 (RPC)** 负载。

1. RPCServer

​	启动一个 RPC 服务器。在这个特定的基准测试中，服务器接收一个请求，然后将同样的数据“回显”给客户端，以此来测量一个完整的请求-响应周期的性能。

```python
class RPCServer(AppConfig):
    # ...
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        # 1. 根据节点类型，选择不同的可执行文件
        exe = 'echoserver_linux' if not isinstance(node, MtcpNode) else \
              'echoserver_mtcp'
        return [
            # 2. 进入基准测试的目录
            'cd /root/tasbench/micro_rpc',
            # 3. 启动服务器进程
            f'./{exe} {self.port} {self.threads} /tmp/guest/mtcp.conf'
            f' {self.max_flows} {self.max_bytes}'
        ]
```

2. RPCClient

​	模拟客户端，向服务器发起大量并发的 RPC 请求。

```python
class RPCClient(AppConfig):
    # ...
    def run_cmds(self, node: NodeConfig) -> tp.List[str]:
        # 1. 同样，根据节点类型选择客户端版本
        exe = 'testclient_linux' if not isinstance(node, MtcpNode) else \
              'testclient_mtcp'
        return [
            'cd /root/tasbench/micro_rpc',
            # 2. 在后台启动客户端负载生成器
            f'./{exe} {self.server_ip} {self.port} ... &',
            # 3. sleep 一段时间来控制测试总时长
            f'sleep {self.time}'
        ]
```

​	启动客户端的命令末尾有一个 `&` 符号，这会让测试程序在**后台**持续运行，不断地向服务器发送请求。

对应 simbricks 中的测试脚本：**rpc_singlecore.py, mtcp_cores.py, mtcp_mpcs.py, mtcp_msgsz.py**



| 应用类别         | 模拟的负载类型           | 考验的网卡核心能力                           |
| ---------------- | ------------------------ | -------------------------------------------- |
| **网络基准测试** | 极限性能、延迟           | **基础数据通路**、DMA引擎、中断处理          |
| **Web 服务器**   | 大量并发、短时连接       | **连接状态管理**、混合流量处理               |
| **分布式共识**   | 对延迟极度敏感的小消息   | **控制通路效率**、**尾延迟控制**             |
| **键值存储**     | 高并发、高请求率小数据包 | **多核扩展性 (RSS)**、多队列性能             |
| **RPC**          | 微服务、请求-响应        | **峰值包处理率 (PPS)**、**高级卸载功能效果** |
